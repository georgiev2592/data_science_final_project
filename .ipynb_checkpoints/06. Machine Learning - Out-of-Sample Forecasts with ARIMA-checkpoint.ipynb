{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning - Out-of-Sample Forecasts with ARIMA\n",
    "\n",
    "In this notebook, we are going to explore a couple of diffrent machine learning models to predict time-series data.\n",
    "\n",
    "Here is a link to all articles/tutorials:\n",
    " - [Time Series Archive](http://machinelearningmastery.com/category/time-series/)\n",
    " \n",
    "Here are links to specific articles:\n",
    " - [How to Make Out-of-Sample Forecasts with ARIMA in Python](http://machinelearningmastery.com/make-sample-forecasts-arima-python/)\n",
    " - [Sensitivity Analysis of History Size to Forecast Skill with ARIMA in Python](http://machinelearningmastery.com/sensitivity-analysis-history-size-forecast-skill-arima-python/)\n",
    " - [Feature Selection for Time Series Forecasting with Python](http://machinelearningmastery.com/feature-selection-time-series-forecasting-python/)\n",
    " - [Simple Time Series Forecasting Models to Test So That You Don’t Fool Yourself](http://machinelearningmastery.com/simple-time-series-forecasting-models/)\n",
    " - [Autoregression Models for Time Series Forecasting With Python](http://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Forecasts with ARIMA\n",
    "\n",
    "This machine learning technique is broken down into the following 5 steps:\n",
    "\n",
    "1. Dataset Description\n",
    "2. Split Dataset\n",
    "3. Develop Model\n",
    "4. One-Step Out-of-Sample Forecast\n",
    "5. Multi-Step Out-of-Sample Forecast\n",
    "\n",
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dew_point_f_avg</th>\n",
       "      <th>dew_point_f_high</th>\n",
       "      <th>dew_point_f_low</th>\n",
       "      <th>events</th>\n",
       "      <th>humidity_%_avg</th>\n",
       "      <th>humidity_%_high</th>\n",
       "      <th>humidity_%_low</th>\n",
       "      <th>precip_in_sum</th>\n",
       "      <th>sea_level_press_in_avg</th>\n",
       "      <th>sea_level_press_in_high</th>\n",
       "      <th>sea_level_press_in_low</th>\n",
       "      <th>temp_f_avg</th>\n",
       "      <th>temp_f_high</th>\n",
       "      <th>temp_f_low</th>\n",
       "      <th>visibility_mi_avg</th>\n",
       "      <th>visibility_mi_high</th>\n",
       "      <th>visibility_mi_low</th>\n",
       "      <th>wind_gust_mph_high</th>\n",
       "      <th>wind_mph_avg</th>\n",
       "      <th>wind_mph_high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-1-1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.15</td>\n",
       "      <td>30.23</td>\n",
       "      <td>30.08</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.23</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.19</td>\n",
       "      <td>52.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.24</td>\n",
       "      <td>30.28</td>\n",
       "      <td>30.17</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td></td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.24</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.20</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td></td>\n",
       "      <td>66.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.15</td>\n",
       "      <td>30.22</td>\n",
       "      <td>30.09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dew_point_f_avg  dew_point_f_high  dew_point_f_low events  \\\n",
       "date                                                                  \n",
       "2012-1-1             44.0              50.0             34.0    Fog   \n",
       "2012-1-2             47.0              52.0             43.0    Fog   \n",
       "2012-1-3             43.0              50.0             37.0    Fog   \n",
       "2012-1-4             42.0              47.0             37.0          \n",
       "2012-1-5             42.0              51.0             36.0          \n",
       "\n",
       "          humidity_%_avg  humidity_%_high  humidity_%_low  precip_in_sum  \\\n",
       "date                                                                       \n",
       "2012-1-1            80.0            100.0            25.0           0.00   \n",
       "2012-1-2            93.0            100.0            63.0           0.00   \n",
       "2012-1-3            85.0            100.0            32.0           0.01   \n",
       "2012-1-4            69.0             96.0            33.0           0.00   \n",
       "2012-1-5            66.0             93.0            23.0           0.00   \n",
       "\n",
       "          sea_level_press_in_avg  sea_level_press_in_high  \\\n",
       "date                                                        \n",
       "2012-1-1                   30.15                    30.23   \n",
       "2012-1-2                   30.23                    30.30   \n",
       "2012-1-3                   30.24                    30.28   \n",
       "2012-1-4                   30.24                    30.30   \n",
       "2012-1-5                   30.15                    30.22   \n",
       "\n",
       "          sea_level_press_in_low  temp_f_avg  temp_f_high  temp_f_low  \\\n",
       "date                                                                    \n",
       "2012-1-1                   30.08        56.0         73.0        39.0   \n",
       "2012-1-2                   30.19        52.0         63.0        42.0   \n",
       "2012-1-3                   30.17        58.0         77.0        39.0   \n",
       "2012-1-4                   30.20        56.0         73.0        39.0   \n",
       "2012-1-5                   30.09        60.0         78.0        42.0   \n",
       "\n",
       "          visibility_mi_avg  visibility_mi_high  visibility_mi_low  \\\n",
       "date                                                                 \n",
       "2012-1-1                6.0                10.0                0.0   \n",
       "2012-1-2                4.0                10.0                0.0   \n",
       "2012-1-3                6.0                10.0                0.0   \n",
       "2012-1-4               10.0                10.0                8.0   \n",
       "2012-1-5               10.0                10.0                7.0   \n",
       "\n",
       "          wind_gust_mph_high  wind_mph_avg  wind_mph_high  \n",
       "date                                                       \n",
       "2012-1-1                 0.0           1.0            8.0  \n",
       "2012-1-2                 0.0           3.0           14.0  \n",
       "2012-1-3                 0.0           2.0           10.0  \n",
       "2012-1-4                 0.0           1.0            9.0  \n",
       "2012-1-5                22.0           4.0           18.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('data/slo_weather_history.csv', index_col=0)\n",
    "\n",
    "# display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1971, Test data: 7\n"
     ]
    }
   ],
   "source": [
    "split_point = len(data) - 7\n",
    "data_train, data_test = data[0:split_point], data[split_point:]\n",
    "\n",
    "print('Training data: %d, Test data: %d' % (len(data_train), len(data_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_helper(x, traces, trace_name, title):\n",
    "    data = []\n",
    "    \n",
    "    for i, trace in enumerate(traces):\n",
    "        # prepare data for plot\n",
    "        data.append(\n",
    "            Scatter(x=np.array(x),\n",
    "                    y=trace,\n",
    "                    name=trace_name[i])\n",
    "        )\n",
    "\n",
    "    layout = Layout({\n",
    "        'title': title\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # plot scores over persistence values\n",
    "    fig = Figure(data=data, layout=layout)\n",
    "    py.iplot(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop Model\n",
    "\n",
    "The data doens't have a strong seasonal component, but we decided to neutralize it and make it stationary by taking the seasonal difference. That is, we can take the observation for a day and subtract the observation from the same day one year ago.\n",
    "\n",
    "We can invert this operation by adding the value of the observation one year ago. We will need to do this to any forecasts made by a model trained on the seasonally adjusted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(data, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(data)):\n",
    "        value = data[i] - data[i - interval]\n",
    "        diff.append(value)\n",
    "    return np.array(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seasonal difference\n",
    "X = data['temp_f_low'].values\n",
    "days_in_year = 365\n",
    "differenced = difference(X, days_in_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1613\n",
      "Model:                     ARMA(7, 1)   Log Likelihood               -4913.777\n",
      "Method:                       css-mle   S.D. of innovations              5.090\n",
      "Date:                Sat, 10 Jun 2017   AIC                           9847.554\n",
      "Time:                        21:15:39   BIC                           9901.412\n",
      "Sample:                             0   HQIC                          9867.545\n",
      "                                                                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6724      0.418      1.608      0.108        -0.147     1.492\n",
      "ar.L1.y       -0.0571      0.272     -0.210      0.834        -0.591     0.477\n",
      "ar.L2.y        0.4525      0.164      2.753      0.006         0.130     0.775\n",
      "ar.L3.y        0.0780      0.032      2.442      0.015         0.015     0.141\n",
      "ar.L4.y       -0.0257      0.029     -0.881      0.378        -0.083     0.031\n",
      "ar.L5.y        0.0072      0.030      0.241      0.810        -0.052     0.066\n",
      "ar.L6.y        0.0121      0.030      0.406      0.685        -0.046     0.071\n",
      "ar.L7.y        0.0320      0.026      1.218      0.223        -0.019     0.083\n",
      "ma.L1.y        0.6556      0.272      2.413      0.016         0.123     1.188\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                 Real           Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.2717           -0.0000j            1.2717           -0.0000\n",
      "AR.2            1.2449           -1.2491j            1.7635           -0.1253\n",
      "AR.3            1.2449           +1.2491j            1.7635            0.1253\n",
      "AR.4           -1.4052           -0.4844j            1.4864           -0.4472\n",
      "AR.5           -1.4052           +0.4844j            1.4864            0.4472\n",
      "AR.6           -0.6653           -1.7706j            1.8914           -0.3072\n",
      "AR.7           -0.6653           +1.7706j            1.8914            0.3072\n",
      "MA.1           -1.5252           +0.0000j            1.5252            0.5000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model = ARIMA(differenced, order=(7,0,1))\n",
    "model_fit = model.fit(disp=0)\n",
    "\n",
    "# print summary of fit model\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Step Out-of-Sample Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA models are great for one-step forecasts.\n",
    "\n",
    "A one-step forecast is a forecast of the very next time step in the sequence from the available data used to fit the model.\n",
    "\n",
    "The statsmodel ARIMAResults object provides a forecast() function for making predictions.\n",
    "\n",
    "By default, this function makes a single step out-of-sample forecast. As such, we can call it directly and make our forecast. The result of the forecast() function is an array containing the forecast value, the standard error of the forecast, and the confidence interval information. Now, we are only interested in the first element of this forecast, as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast: 53.500663, Actual: 57.000000\n"
     ]
    }
   ],
   "source": [
    "# one-step out-of sample forecast\n",
    "forecast = model_fit.forecast()[0]\n",
    "\n",
    "# invert the differenced forecast to something usable\n",
    "forecast = inverse_difference(X, forecast, days_in_year)\n",
    "\n",
    "print('Forecast: %f, Actual: %f' % (forecast, data_test.iloc[0]['temp_f_low']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Step Out-of-Sample Forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make multi-step forecasts using the forecast() function.\n",
    "\n",
    "It is common with weather data to make one week (7-day) forecasts, so in this section we will look at predicting the minimum daily temperature for the next 7 out-of-sample time steps.\n",
    "\n",
    "The forecast() function has an argument called steps that allows you to specify the number of time steps to forecast. By default, this argument is set to 1 for a one-step out-of-sample forecast. We can set it to 7 to get a forecast for the next 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1 -- Forecast: 53.500663, Actual: 57.000000\n",
      "Day 2 -- Forecast: 53.421839, Actual: 54.000000\n",
      "Day 3 -- Forecast: 52.347355, Actual: 48.000000\n",
      "Day 4 -- Forecast: 53.944593, Actual: 53.000000\n",
      "Day 5 -- Forecast: 53.859196, Actual: 53.000000\n",
      "Day 6 -- Forecast: 55.152610, Actual: 52.000000\n",
      "Day 7 -- Forecast: 57.190460, Actual: 51.000000\n",
      "Test RMSE: 3.409\n"
     ]
    }
   ],
   "source": [
    "# multi-step out-of-sample forecast\n",
    "forecast = model_fit.forecast(steps=7)[0]\n",
    "\n",
    "# invert the differenced forecast to something usable\n",
    "history = [x for x in X]\n",
    "day = 1\n",
    "\n",
    "tests = []\n",
    "predictions = []\n",
    "\n",
    "for yhat in forecast:\n",
    "    test = data_test.iloc[day - 1]['temp_f_low']\n",
    "    predicted = inverse_difference(history, yhat, days_in_year)\n",
    "    \n",
    "    print('Day %d -- Forecast: %f, Actual: %f' % (day, predicted, test))\n",
    "    history.append(predicted)\n",
    "    day += 1\n",
    "    \n",
    "    tests.append(test)\n",
    "    predictions.append(predicted)\n",
    "    \n",
    "test_score = np.sqrt(mean_squared_error(tests, predictions))\n",
    "print('Test RMSE: %.3f' % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "name": "Test",
         "type": "scatter",
         "x": [
          "2017-5-25",
          "2017-5-26",
          "2017-5-27",
          "2017-5-28",
          "2017-5-29",
          "2017-5-30",
          "2017-5-31"
         ],
         "y": [
          57,
          54,
          48,
          53,
          53,
          52,
          51
         ]
        },
        {
         "name": "Forecast",
         "type": "scatter",
         "x": [
          "2017-5-25",
          "2017-5-26",
          "2017-5-27",
          "2017-5-28",
          "2017-5-29",
          "2017-5-30",
          "2017-5-31"
         ],
         "y": [
          53.50066265369113,
          53.42183884968637,
          52.34735467222528,
          53.94459331058451,
          53.85919630518911,
          55.15260953199911,
          57.19046024346998
         ]
        }
       ],
       "layout": {
        "title": "Line Plot of Predicted Values vs Test Dataset - San Luis Obispo, CA"
       }
      },
      "text/html": [
       "<div id=\"39c55445-1daf-4254-86f7-8fd5704b03a0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"39c55445-1daf-4254-86f7-8fd5704b03a0\", [{\"name\": \"Test\", \"x\": [\"2017-5-25\", \"2017-5-26\", \"2017-5-27\", \"2017-5-28\", \"2017-5-29\", \"2017-5-30\", \"2017-5-31\"], \"y\": [57.0, 54.0, 48.0, 53.0, 53.0, 52.0, 51.0], \"type\": \"scatter\"}, {\"name\": \"Forecast\", \"x\": [\"2017-5-25\", \"2017-5-26\", \"2017-5-27\", \"2017-5-28\", \"2017-5-29\", \"2017-5-30\", \"2017-5-31\"], \"y\": [53.50066265369113, 53.42183884968637, 52.34735467222528, 53.94459331058451, 53.85919630518911, 55.15260953199911, 57.19046024346998], \"type\": \"scatter\"}], {\"title\": \"Line Plot of Predicted Values vs Test Dataset - San Luis Obispo, CA\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"39c55445-1daf-4254-86f7-8fd5704b03a0\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"39c55445-1daf-4254-86f7-8fd5704b03a0\", [{\"name\": \"Test\", \"x\": [\"2017-5-25\", \"2017-5-26\", \"2017-5-27\", \"2017-5-28\", \"2017-5-29\", \"2017-5-30\", \"2017-5-31\"], \"y\": [57.0, 54.0, 48.0, 53.0, 53.0, 52.0, 51.0], \"type\": \"scatter\"}, {\"name\": \"Forecast\", \"x\": [\"2017-5-25\", \"2017-5-26\", \"2017-5-27\", \"2017-5-28\", \"2017-5-29\", \"2017-5-30\", \"2017-5-31\"], \"y\": [53.50066265369113, 53.42183884968637, 52.34735467222528, 53.94459331058451, 53.85919630518911, 55.15260953199911, 57.19046024346998], \"type\": \"scatter\"}], {\"title\": \"Line Plot of Predicted Values vs Test Dataset - San Luis Obispo, CA\"}, {\"showLink\": true, \"linkText\": \"Export to plot.ly\"})});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot predictions vs observations\n",
    "plot_helper(data_test.index, [tests, predictions], ['Test', 'Forecast'], 'Line Plot of Predicted Values vs Test Dataset - San Luis Obispo, CA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
