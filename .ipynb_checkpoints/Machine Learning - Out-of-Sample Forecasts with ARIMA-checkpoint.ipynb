{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine Learning - Out-of-Sample Forecasts with ARIMA\n",
    "\n",
    "In this notebook, we are going to explore a couple of diffrent machine learning models to predict time-series data.\n",
    "\n",
    "Here is a link to all articles/tutorials:\n",
    " - [Time Series Archive](http://machinelearningmastery.com/category/time-series/)\n",
    " \n",
    "Here are links to specific articles:\n",
    " - [How to Make Out-of-Sample Forecasts with ARIMA in Python](http://machinelearningmastery.com/make-sample-forecasts-arima-python/)\n",
    " - [Sensitivity Analysis of History Size to Forecast Skill with ARIMA in Python](http://machinelearningmastery.com/sensitivity-analysis-history-size-forecast-skill-arima-python/)\n",
    " - [Feature Selection for Time Series Forecasting with Python](http://machinelearningmastery.com/feature-selection-time-series-forecasting-python/)\n",
    " - [Simple Time Series Forecasting Models to Test So That You Don’t Fool Yourself](http://machinelearningmastery.com/simple-time-series-forecasting-models/)\n",
    " - [Autoregression Models for Time Series Forecasting With Python](http://machinelearningmastery.com/autoregression-models-time-series-forecasting-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Sample Forecasts with ARIMA\n",
    "\n",
    "This machine learning technique is broken down into the following 5 steps:\n",
    "\n",
    "1. Dataset Description\n",
    "2. Split Dataset\n",
    "3. Develop Model\n",
    "4. One-Step Out-of-Sample Forecast\n",
    "5. Multi-Step Out-of-Sample Forecast\n",
    "\n",
    "### Dataset Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dew_point_f_avg</th>\n",
       "      <th>dew_point_f_high</th>\n",
       "      <th>dew_point_f_low</th>\n",
       "      <th>events</th>\n",
       "      <th>humidity_%_avg</th>\n",
       "      <th>humidity_%_high</th>\n",
       "      <th>humidity_%_low</th>\n",
       "      <th>precip_in_sum</th>\n",
       "      <th>sea_level_press_in_avg</th>\n",
       "      <th>sea_level_press_in_high</th>\n",
       "      <th>sea_level_press_in_low</th>\n",
       "      <th>temp_f_avg</th>\n",
       "      <th>temp_f_high</th>\n",
       "      <th>temp_f_low</th>\n",
       "      <th>visibility_mi_avg</th>\n",
       "      <th>visibility_mi_high</th>\n",
       "      <th>visibility_mi_low</th>\n",
       "      <th>wind_gust_mph_high</th>\n",
       "      <th>wind_mph_avg</th>\n",
       "      <th>wind_mph_high</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-1-1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.15</td>\n",
       "      <td>30.23</td>\n",
       "      <td>30.08</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-2</th>\n",
       "      <td>47.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>93.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.23</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.19</td>\n",
       "      <td>52.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-3</th>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Fog</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30.24</td>\n",
       "      <td>30.28</td>\n",
       "      <td>30.17</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-4</th>\n",
       "      <td>42.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td></td>\n",
       "      <td>69.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.24</td>\n",
       "      <td>30.30</td>\n",
       "      <td>30.20</td>\n",
       "      <td>56.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-1-5</th>\n",
       "      <td>42.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td></td>\n",
       "      <td>66.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.15</td>\n",
       "      <td>30.22</td>\n",
       "      <td>30.09</td>\n",
       "      <td>60.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dew_point_f_avg  dew_point_f_high  dew_point_f_low events  \\\n",
       "date                                                                  \n",
       "2012-1-1             44.0              50.0             34.0    Fog   \n",
       "2012-1-2             47.0              52.0             43.0    Fog   \n",
       "2012-1-3             43.0              50.0             37.0    Fog   \n",
       "2012-1-4             42.0              47.0             37.0          \n",
       "2012-1-5             42.0              51.0             36.0          \n",
       "\n",
       "          humidity_%_avg  humidity_%_high  humidity_%_low  precip_in_sum  \\\n",
       "date                                                                       \n",
       "2012-1-1            80.0            100.0            25.0           0.00   \n",
       "2012-1-2            93.0            100.0            63.0           0.00   \n",
       "2012-1-3            85.0            100.0            32.0           0.01   \n",
       "2012-1-4            69.0             96.0            33.0           0.00   \n",
       "2012-1-5            66.0             93.0            23.0           0.00   \n",
       "\n",
       "          sea_level_press_in_avg  sea_level_press_in_high  \\\n",
       "date                                                        \n",
       "2012-1-1                   30.15                    30.23   \n",
       "2012-1-2                   30.23                    30.30   \n",
       "2012-1-3                   30.24                    30.28   \n",
       "2012-1-4                   30.24                    30.30   \n",
       "2012-1-5                   30.15                    30.22   \n",
       "\n",
       "          sea_level_press_in_low  temp_f_avg  temp_f_high  temp_f_low  \\\n",
       "date                                                                    \n",
       "2012-1-1                   30.08        56.0         73.0        39.0   \n",
       "2012-1-2                   30.19        52.0         63.0        42.0   \n",
       "2012-1-3                   30.17        58.0         77.0        39.0   \n",
       "2012-1-4                   30.20        56.0         73.0        39.0   \n",
       "2012-1-5                   30.09        60.0         78.0        42.0   \n",
       "\n",
       "          visibility_mi_avg  visibility_mi_high  visibility_mi_low  \\\n",
       "date                                                                 \n",
       "2012-1-1                6.0                10.0                0.0   \n",
       "2012-1-2                4.0                10.0                0.0   \n",
       "2012-1-3                6.0                10.0                0.0   \n",
       "2012-1-4               10.0                10.0                8.0   \n",
       "2012-1-5               10.0                10.0                7.0   \n",
       "\n",
       "          wind_gust_mph_high  wind_mph_avg  wind_mph_high  \n",
       "date                                                       \n",
       "2012-1-1                 0.0           1.0            8.0  \n",
       "2012-1-2                 0.0           3.0           14.0  \n",
       "2012-1-3                 0.0           2.0           10.0  \n",
       "2012-1-4                 0.0           1.0            9.0  \n",
       "2012-1-5                22.0           4.0           18.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv('data/slo_weather_history.csv', index_col=0)\n",
    "\n",
    "# display first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 1971, Test data: 7\n"
     ]
    }
   ],
   "source": [
    "split_point = len(data) - 7\n",
    "data_train, data_test = data[0:split_point], data[split_point:]\n",
    "\n",
    "print('Training data: %d, Test data: %d' % (len(data_train), len(data_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop Model\n",
    "\n",
    "The data doens't have a strong seasonal component, but we decided to neutralize it and make it stationary by taking the seasonal difference. That is, we can take the observation for a day and subtract the observation from the same day one year ago.\n",
    "\n",
    "We can invert this operation by adding the value of the observation one year ago. We will need to do this to any forecasts made by a model trained on the seasonally adjusted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a differenced series\n",
    "def difference(data, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(data)):\n",
    "        value = data[i] - data[i - interval]\n",
    "        diff.append(value)\n",
    "    return np.array(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# invert differenced value\n",
    "def inverse_difference(history, yhat, interval=1):\n",
    "    return yhat + history[-interval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# seasonal difference\n",
    "X = data['temp_f_low'].values\n",
    "days_in_year = 365\n",
    "differenced = difference(X, days_in_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              ARMA Model Results                              \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                 1613\n",
      "Model:                     ARMA(7, 1)   Log Likelihood               -4913.777\n",
      "Method:                       css-mle   S.D. of innovations              5.090\n",
      "Date:                Sat, 10 Jun 2017   AIC                           9847.554\n",
      "Time:                        20:26:06   BIC                           9901.412\n",
      "Sample:                             0   HQIC                          9867.545\n",
      "                                                                              \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.6724      0.418      1.608      0.108        -0.147     1.492\n",
      "ar.L1.y       -0.0571      0.272     -0.210      0.834        -0.591     0.477\n",
      "ar.L2.y        0.4525      0.164      2.753      0.006         0.130     0.775\n",
      "ar.L3.y        0.0780      0.032      2.442      0.015         0.015     0.141\n",
      "ar.L4.y       -0.0257      0.029     -0.881      0.378        -0.083     0.031\n",
      "ar.L5.y        0.0072      0.030      0.241      0.810        -0.052     0.066\n",
      "ar.L6.y        0.0121      0.030      0.406      0.685        -0.046     0.071\n",
      "ar.L7.y        0.0320      0.026      1.218      0.223        -0.019     0.083\n",
      "ma.L1.y        0.6556      0.272      2.413      0.016         0.123     1.188\n",
      "                                    Roots                                    \n",
      "=============================================================================\n",
      "                 Real           Imaginary           Modulus         Frequency\n",
      "-----------------------------------------------------------------------------\n",
      "AR.1            1.2717           -0.0000j            1.2717           -0.0000\n",
      "AR.2            1.2449           -1.2491j            1.7635           -0.1253\n",
      "AR.3            1.2449           +1.2491j            1.7635            0.1253\n",
      "AR.4           -1.4052           -0.4844j            1.4864           -0.4472\n",
      "AR.5           -1.4052           +0.4844j            1.4864            0.4472\n",
      "AR.6           -0.6653           -1.7706j            1.8914           -0.3072\n",
      "AR.7           -0.6653           +1.7706j            1.8914            0.3072\n",
      "MA.1           -1.5252           +0.0000j            1.5252            0.5000\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "model = ARIMA(differenced, order=(7,0,1))\n",
    "model_fit = model.fit(disp=0)\n",
    "\n",
    "# print summary of fit model\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Step Out-of-Sample Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast: 53.500663, Actual: 57.000000\n"
     ]
    }
   ],
   "source": [
    "# one-step out-of sample forecast\n",
    "forecast = model_fit.forecast()[0]\n",
    "\n",
    "# invert the differenced forecast to something usable\n",
    "forecast = inverse_difference(X, forecast, days_in_year)\n",
    "\n",
    "print('Forecast: %f, Actual: %f' % (forecast, data_test.iloc[0]['temp_f_low']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Step Out-of-Sample Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1 -- Forecast: 53.500663, Actual: 57.000000\n",
      "Day 2 -- Forecast: 53.421839, Actual: 54.000000\n",
      "Day 3 -- Forecast: 52.347355, Actual: 48.000000\n",
      "Day 4 -- Forecast: 53.944593, Actual: 53.000000\n",
      "Day 5 -- Forecast: 53.859196, Actual: 53.000000\n",
      "Day 6 -- Forecast: 55.152610, Actual: 52.000000\n",
      "Day 7 -- Forecast: 57.190460, Actual: 51.000000\n",
      "Test RMSE: 3.409\n"
     ]
    }
   ],
   "source": [
    "# multi-step out-of-sample forecast\n",
    "forecast = model_fit.forecast(steps=7)[0]\n",
    "\n",
    "# invert the differenced forecast to something usable\n",
    "history = [x for x in X]\n",
    "day = 1\n",
    "\n",
    "tests = []\n",
    "predictions = []\n",
    "\n",
    "for yhat in forecast:\n",
    "    test = data_test.iloc[day - 1]['temp_f_low']\n",
    "    predicted = inverse_difference(history, yhat, days_in_year)\n",
    "    \n",
    "    print('Day %d -- Forecast: %f, Actual: %f' % (day, predicted, test))\n",
    "    history.append(predicted)\n",
    "    day += 1\n",
    "    \n",
    "    tests.append(test)\n",
    "    predictions.append(predicted)\n",
    "    \n",
    "test_score = np.sqrt(mean_squared_error(tests, predictions))\n",
    "print('Test RMSE: %.3f' % test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
